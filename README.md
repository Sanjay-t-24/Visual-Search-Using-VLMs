# Visual Search using Vision-Language Models (VLM)

> A Google Lens-inspired project built from scratch to perform an intelligent **visual search** using **Vision-Language Models (VLM)** â€” enabling object detection, product recognition, and place identification across multiple domains.

---

## âœ¨ Project Overview

This project implements a **Visual Search** engine that accepts an image as input and outputs detailed descriptions, object identification, and potential matches from a database. It is designed to be:

- **E-commerce ready**: Recognize and retrieve products based on images, enabling seamless product discovery and recommendation.
- **Medical-field applicable**: Search and identify medical tools, equipment, and healthcare-related places, aiding medical documentation and resource identification.
- **Google Colab compatible**: Lightweight and scalable for rapid prototyping and easy demonstrations.

We leverage **Vision-Language Models (VLM)** to bridge the gap between visual and textual understanding.

> ğŸ“¢ **Note**: The current demo is tailored for **e-commerce product search**, showcasing product identification and retrieval functionalities.

---

## ğŸ› ï¸ Features

- ğŸ” **Image-to-Text Understanding**: Generate captions and labels for input images.
- ğŸ›’ **Product Recognition**: Match products from a given database (for e-commerce).
- ğŸ¥ **Medical Image Search**: Identify and retrieve medical tools or locations from images (expandable).
- ğŸ“ **Place Recognition**: Identify landmarks and locations from images.
- ğŸ¯ **Zero-shot Learning**: Minimal or no task-specific training needed.
- âš¡ **Lightweight Deployment**: Easily run on Google Colab or edge devices.
- ğŸ›¡ï¸ **Scalable**: Extendable to multiple domains like healthcare, fashion, education, and more.

---

## ğŸš€ Tech Stack

- **Vision-Language Models**: CLIP / BLIP / BLIP-2 / Florence / LLaVA
- **Python 3**
- **TensorFlow / PyTorch**
- **FAISS** (for fast similarity search)
- **OpenCV** (for image processing)
- **Streamlit** (for optional web interface)

---

## ğŸ“ Project Structure

```
visual-search-vlm/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ database_images/       # Images to search from
â”‚   â””â”€â”€ query_images/          # Query images
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ vlm_model.py           # Load and use pre-trained VLM
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ image_utils.py         # Preprocessing utilities
â”‚   â”œâ”€â”€ search_utils.py        # Feature extraction and search
â”‚
â”œâ”€â”€ app.py                     # Main application script
â”œâ”€â”€ requirements.txt           # Required Python libraries
â””â”€â”€ README.md                  # Project documentation
```

---

## âš™ï¸ How It Works

1. **Feature Extraction**: Use a pre-trained VLM to extract visual and textual features from database and query images.
2. **Embedding Search**: Store embeddings using FAISS for fast similarity search.
3. **Matching**: Given a query image, find the most similar database entries based on feature embeddings.
4. **Result Visualization**: Display the top matching results along with descriptions.

---

## ğŸ§‘â€ğŸ’» Setup Instructions

1. Clone this repository:
   ```bash
   git clone https://github.com/your-username/visual-search-vlm.git
   cd visual-search-vlm
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. (Optional) If running on Colab, upload your `data/` folder.

4. Run the application:
   ```bash
   python app.py
   ```

---

ğŸ“Š **Demo (E-commerce Focused)**

Input Image | Similar Products
:---|:---
The first screenshot shows the input image given to the system. | ![ss1](https://github.com/user-attachments/assets/04886d01-a6ed-4b0f-9b4e-55c5b53d51b1)
The second screenshot displays the similar products found and links to the products. | ![ss2](https://github.com/user-attachments/assets/84f2953b-81e6-407f-aff7-0fbe95045217)

All screenshots are stored in the `output/` folder.

---

## ğŸ§© Future Work

- Expand the database for **medical image search** (medical tools, healthcare places).
- Integrate **multimodal retrieval** (image + text-based search).
- Optimize for **edge deployment** (TensorFlow Lite, ONNX).
- Build a **full-stack application** with real-time upload and search capabilities.
- Enhance cross-domain support for applications beyond e-commerce and healthcare.

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!

1. Fork the repository.
2. Create a new branch (`git checkout -b feature-branch`).
3. Make your changes.
4. Submit a pull request.

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸŒŸ Acknowledgements

- [OpenAI CLIP](https://github.com/openai/CLIP)
- [Salesforce BLIP](https://github.com/salesforce/BLIP)
- [FAISS by Facebook AI](https://github.com/facebookresearch/faiss)
